---
title: "Predictive model classification in the context of an unbalanced sample"
author: "Thibault FUCHEZ"
date: "27/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Package

```{r}
library (tidyverse) # collection of packages for data analysis
library(ISLR) # Data for an Introduction to Statistical Learning with Applications in R/ contain the "Caravan / insurance data" 
library(caret) # Classification And REgression Training
```

# Applied Predictive modeling - Mx Kuhn, ... (16.9 Computing)

```{r}
data <- Caravan
summary(data)
str(data)
plot(data$Purchase)
```

The training and test sets were created using stratiﬁed random sampling.

First, split the training set off:

```{r}
set.seed(156)
split1 <- createDataPartition(data$Purchase, p = .7)[[1]]
other <- data[-split1,]
training <- data[ split1,]
```

Now create the evaluation and test sets :

```{r}
set.seed(934)
split2 <- createDataPartition(data$Purchase, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]
```

Determine the predictor names :

```{r}
predictors <- names(training)[names(training) != "Purchase"]
```

Dummy variables are useful for several models being ﬁt in this section.
The randomForest function has a limitation that all factor predictors must not have more than 32 levels. (sure??)

The customer type predictor has 39 levels, so a predictor set of dummy variables is created for this and other models using the model.matrix function:
