<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Metrics for classification tasks | Models of classification in context of imbalanced datas</title>
  <meta name="description" content="First try of bookdown" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Metrics for classification tasks | Models of classification in context of imbalanced datas" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="First try of bookdown" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Metrics for classification tasks | Models of classification in context of imbalanced datas" />
  
  <meta name="twitter:description" content="First try of bookdown" />
  

<meta name="author" content="Thibault Fuchez" />


<meta name="date" content="2021-07-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="classifiers.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abstract"><i class="fa fa-check"></i><b>1.1</b> Abstract</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#document-format"><i class="fa fa-check"></i><b>1.2</b> Document format</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html"><i class="fa fa-check"></i><b>2</b> Metrics for classification tasks</a>
<ul>
<li class="chapter" data-level="2.1" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#the-foundation-of-the-metrics-the-confusion-matrix"><i class="fa fa-check"></i><b>2.1</b> The foundation of the metrics: The Confusion Matrix</a></li>
<li class="chapter" data-level="2.2" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#accuracy-and-error-rate"><i class="fa fa-check"></i><b>2.2</b> Accuracy and error rate</a></li>
<li class="chapter" data-level="2.3" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#true-positive-rate"><i class="fa fa-check"></i><b>2.3</b> True Positive rate</a></li>
<li class="chapter" data-level="2.4" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#true-negative-and-false-positive-rate"><i class="fa fa-check"></i><b>2.4</b> True Negative and False positive rate</a></li>
<li class="chapter" data-level="2.5" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#positive-prediction-value-precision"><i class="fa fa-check"></i><b>2.5</b> Positive prediction value : Precision</a></li>
<li class="chapter" data-level="2.6" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#f-measure"><i class="fa fa-check"></i><b>2.6</b> F-measure</a></li>
<li class="chapter" data-level="2.7" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#kappa"><i class="fa fa-check"></i><b>2.7</b> Kappa</a></li>
<li class="chapter" data-level="2.8" data-path="metrics-for-classification-tasks.html"><a href="metrics-for-classification-tasks.html#roc-curve"><i class="fa fa-check"></i><b>2.8</b> ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classifiers.html"><a href="classifiers.html"><i class="fa fa-check"></i><b>3</b> Classifiers</a>
<ul>
<li class="chapter" data-level="3.1" data-path="classifiers.html"><a href="classifiers.html#lda"><i class="fa fa-check"></i><b>3.1</b> LDA</a></li>
<li class="chapter" data-level="3.2" data-path="classifiers.html"><a href="classifiers.html#presentation"><i class="fa fa-check"></i><b>3.2</b> Presentation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="classifiers.html"><a href="classifiers.html#learning-lda-model"><i class="fa fa-check"></i><b>3.2.1</b> Learning LDA model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="classifiers.html"><a href="classifiers.html#logistic-regression"><i class="fa fa-check"></i><b>3.3</b> logistic regression</a></li>
<li class="chapter" data-level="3.4" data-path="classifiers.html"><a href="classifiers.html#svm"><i class="fa fa-check"></i><b>3.4</b> SVM</a></li>
<li class="chapter" data-level="3.5" data-path="classifiers.html"><a href="classifiers.html#classification-tree"><i class="fa fa-check"></i><b>3.5</b> classification tree</a></li>
<li class="chapter" data-level="3.6" data-path="classifiers.html"><a href="classifiers.html#random-forest"><i class="fa fa-check"></i><b>3.6</b> random forest</a></li>
<li class="chapter" data-level="3.7" data-path="classifiers.html"><a href="classifiers.html#naives-bayes"><i class="fa fa-check"></i><b>3.7</b> Naives bayes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="remedies.html"><a href="remedies.html"><i class="fa fa-check"></i><b>4</b> Remedies</a>
<ul>
<li class="chapter" data-level="4.1" data-path="remedies.html"><a href="remedies.html#pre-processing-resampling"><i class="fa fa-check"></i><b>4.1</b> Pre processing resampling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="remedies.html"><a href="remedies.html#random-up-and-down-sample"><i class="fa fa-check"></i><b>4.1.1</b> Random Up and Down sample :</a></li>
<li class="chapter" data-level="4.1.2" data-path="remedies.html"><a href="remedies.html#rose"><i class="fa fa-check"></i><b>4.1.2</b> ROSE</a></li>
<li class="chapter" data-level="4.1.3" data-path="remedies.html"><a href="remedies.html#smote-family-smotenc-blsmote-adasyn"><i class="fa fa-check"></i><b>4.1.3</b> Smote family (smoteNC, BLSMOTE, ADASYN)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="remedies.html"><a href="remedies.html#learning-method-tuning"><i class="fa fa-check"></i><b>4.2</b> Learning method tuning</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="remedies.html"><a href="remedies.html#metaparameters-tuning"><i class="fa fa-check"></i><b>4.2.1</b> Metaparameters tuning</a></li>
<li class="chapter" data-level="4.2.2" data-path="remedies.html"><a href="remedies.html#weighted-class"><i class="fa fa-check"></i><b>4.2.2</b> Weighted class</a></li>
<li class="chapter" data-level="4.2.3" data-path="remedies.html"><a href="remedies.html#direct-sensitive-learning-with-cart-classifer"><i class="fa fa-check"></i><b>4.2.3</b> direct sensitive learning with cart classifer</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="remedies.html"><a href="remedies.html#post-processing-threesholding"><i class="fa fa-check"></i><b>4.3</b> post-processing threesholding</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>5</b> Applications</a>
<ul>
<li class="chapter" data-level="5.1" data-path="applications.html"><a href="applications.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="applications.html"><a href="applications.html#first-models"><i class="fa fa-check"></i><b>5.2</b> First Models</a></li>
<li class="chapter" data-level="5.3" data-path="applications.html"><a href="applications.html#preprocessing-resampling-methods"><i class="fa fa-check"></i><b>5.3</b> Preprocessing: Resampling methods</a></li>
<li class="chapter" data-level="5.4" data-path="applications.html"><a href="applications.html#direct-cost-sensisitive-learnig"><i class="fa fa-check"></i><b>5.4</b> Direct cost sensisitive learnig</a></li>
<li class="chapter" data-level="5.5" data-path="applications.html"><a href="applications.html#post-processing-threesholding-1"><i class="fa fa-check"></i><b>5.5</b> Post processing Threesholding</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>6</b> Summary</a>
<ul>
<li class="chapter" data-level="6.1" data-path="summary.html"><a href="summary.html#different-strategies"><i class="fa fa-check"></i><b>6.1</b> different strategies :</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Models of classification in context of imbalanced datas</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="metrics-for-classification-tasks" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Metrics for classification tasks</h1>
<p>Understanding if a model is a good classifier or not requires a good comprehension of the predictions. We want to know the global effiency but some specific element too. Is classifier better in predicting one or the other class? What are the strength and weakness of the model? Can we be confident towards the results, haw can we know they are not due to chance?</p>
<p>In order to compare the performance’s models, we use different “metrics.” Our tools reliability is highly dependent on the data structure. In our case, the imbalanced sample of data classes has to be taken into account in order to find the metrics which allows to give a good evaluation of our models.</p>
<div id="the-foundation-of-the-metrics-the-confusion-matrix" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> The foundation of the metrics: The Confusion Matrix</h2>
<p>The confusion matrix presents the results obtained by a given classifier. This table provides the instances that were correctly classified (True Positive and True negative), and the instances that were wrongly classified (False Positive and False negative).
From this table, we can calculate all the metrics described below</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Predicted
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Positive
</th>
<th style="text-align:left;">
Negative
</th>
</tr>
</thead>
<tbody>
<tr grouplength="2">
<td colspan="3" style="border-bottom: 1px solid;">
<strong>True</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Positive
</td>
<td style="text-align:left;">
TP
</td>
<td style="text-align:left;">
FN
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Negative
</td>
<td style="text-align:left;">
FP
</td>
<td style="text-align:left;">
TN
</td>
</tr>
</tbody>
</table>
</div>
<div id="accuracy-and-error-rate" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Accuracy and error rate</h2>
<p><span class="math display">\[error = \frac{FP + FN}{TN+TP+FP+FN}\]</span></p>
<p><span class="math display">\[accuracy = 1 - error\]</span>
The first metrics is obviously the global accuracy and its complement the error rate. It is the most frequently used to estimate the performance of a model. If accuracy is too low, we deduce that our learning algorithm is globally inefficient. However In the context of imbalanced data set, accuracy is not suitable. Indeed, because of the massive representation of the negative class, and as the classifiers failed to identify the positive class, we reach a high value of accuracy. For instance, if only 10% of the cases belong to the positive class and the classifiers predicts all cases as negative, accuracy will be at 90%.
This is worthless when users objectives is to predict the rare cases.</p>
<p>To reflect more closely the users needs and priorities, several performance measure exist.</p>
</div>
<div id="true-positive-rate" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> True Positive rate</h2>
<p><span class="math display">\[TP_{rate} = \frac{TP}{TP+FN} = \frac{TP}{P_{real}}\]</span></p>
<p>Also called sensitivity, recall or detection power. I personally prefer the term detection power because it is more explicit. It is the ratio of the value predicted as positive and which are actually positive among all the real positive. This is the ability of our classifier to detect the positive cases.</p>
</div>
<div id="true-negative-and-false-positive-rate" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> True Negative and False positive rate</h2>
<p>Also called specificity. It is the ratio of the value predicted as negative and which are actually negative among all the real negative case.</p>
<p><span class="math display">\[TN_{rate} = \frac{TN}{TN+FP}\]</span></p>
<p>I prefer its complement, the False positive rate, also called False alarm. Indeed, the term “False alarm” is more relevant than specificity.</p>
<p><span class="math display">\[FP_{rate} = \frac{FP}{TN+FP} = 1 - TN_{rate}\]</span>
TPrate (detection power) and FP rate (False alarm) are often quote in the literature as benefits and costs, respectively. These terms refers to a central point of our problematic. Indeed, a key point to find good remedies is to make a trade-off between what it cost in terms of False alarm and the benefits gained in terms of detection power.</p>
</div>
<div id="positive-prediction-value-precision" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Positive prediction value : Precision</h2>
<p><span class="math display">\[PP_{value} = \frac{TP}{TP+FP} =  \frac{TP}{P_{pred}} \]</span></p>
<p>The precision measures the rate of True positive among all cases predicted as positive.</p>
</div>
<div id="f-measure" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> F-measure</h2>
<p>The F-measure is a combination of both precision and recall. This metric value is high when both recall (a measure of completeness) and precision ( a measure of exactness) are high. Hence, this metrics is particulary suitable on predicting the case that matter to the user.</p>
<p><span class="math display">\[F_\beta = \frac{(1+\beta^2) \times recall \times precision}{\beta^2 \times recall + precision}\]</span>
Beta is a coefficient to adjust the weight of recall against precision. In this paper, we choose a value of 1 which give the same weights to recall and precision.</p>
</div>
<div id="kappa" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> Kappa</h2>
<p><span class="math display">\[K = \frac{P_{agree}-P_{chance}}{1-P_{chance}}\]</span></p>
<p><span class="math display">\[P_{agree} = \frac{TP + FN} {number \ of \ cases} \]</span>
<span class="math display">\[P_{chance} = \frac{P_{pre} \times P_{act}}{number \ of \ cases^2}+\frac{N_{pre} \times N_{act}}{number \ of \ cases^2}\]</span></p>
<p>Kappa is a very interesting metrics in context of imbalanced datas.
The calculation is based on the difference between how much agreement(positive) is actually present (“observed”) compared to how much positive would be expected to be present by chance alone (“expected”). We want to know how different the observed positive are from the expected. Kappa is a measure of this difference<span class="citation">(<a href="#ref-kappa" role="doc-biblioref">McHugh 2015</a>)</span>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
score
</th>
<th style="text-align:left;">
app
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
&lt; 0
</td>
<td style="text-align:left;">
Less than chance agreement
</td>
</tr>
<tr>
<td style="text-align:left;">
0.01-0.20
</td>
<td style="text-align:left;">
slight agreement
</td>
</tr>
<tr>
<td style="text-align:left;">
0.21– 0.40
</td>
<td style="text-align:left;">
Fair agreement
</td>
</tr>
<tr>
<td style="text-align:left;">
0.41–0.60
</td>
<td style="text-align:left;">
Moderate agreement
</td>
</tr>
<tr>
<td style="text-align:left;">
0.61–0.80
</td>
<td style="text-align:left;">
Substantial agreement
</td>
</tr>
<tr>
<td style="text-align:left;">
0.81–0.99
</td>
<td style="text-align:left;">
Almost perfect agreement
</td>
</tr>
</tbody>
</table>
</div>
<div id="roc-curve" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> ROC Curve</h2>
<p>A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.</p>
<p>The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.</p>
<p><img src="Roc.jpg" style="display: block; margin: auto;" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-kappa" class="csl-entry">
McHugh, Mary L. 2015. <em>Interrater Reliability: The Kappa Statistic</em>. Biochem Med.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classifiers.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Test_book.pdf", "Test_book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
