---
title: "spotify"
author: "Thibault FUCHEZ"
date: "04/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Package

```{r}
library (tidyverse) # collection of packages for data analysis
library(caret) # Classification And REgression Training
library(pROC) # Tools for visualizing, smoothing and comparing ROC.
library(ROCR) # evaluating and visualizing classifier performance
library(lubridate) # R commands for date-times
library(tidymodels) #  collection of packages for modeling and machine learning using tidyverse principles. pre-process/train/validate
library(MASS) # Modern Applied Statistics with S" for regression and classification
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(randomForest) # ensemble learning method with multitude of decision tree 
library(doParallel) # paralléliser le calcul pour que ce soit plus rapide en créant un cluster de cœurs.
library(parallel) # détection du nombre de coeurs
library(ranger) # A Fast Implementation of Random Forests. (tune rf)
library(e1071) # Misc Functions of the Department of Statistics, Probability Theory Group / for svm, tune, predict, ...
library(kableExtra) # Create Awesome HTML Table
library(smotefamily) # Synthetic Minority Oversampling TEchnique
library(ROSE) # Generation of synthetic data by Randomly Over Sampling Examples
```

# idée de plan et qq notes 

Penser à citer les articles et à expliciter rapidement les notions mathéatiques derrière les concepts (comment le modèle apprend -formule et grap)

O. Préparation des bases de données et création des fonctions utilisée par la suite  ??

1. Définition problèmatique : 
  1.1 Préparation des bases de données
  1.2 Création des fonctions pour automatiser le code 
  1.3 Observation des résultats de classification sur échantillons déséquilibrés (3 ou 4 base de données). On fait tourner les modèles et on observe que la machine apprend mal avec des modèles basés sur une classe déséquilibrée. 

2. Solutions : 

  2.1 Optimiser les paramètres : 
    2.1.1 Présentation et définition (définition et appli sur les modèles)
    2.1.2 Mesure de l'efficacité de la technique
    2.1.3 Avantages et inconvénients de la technique
  
  2.2 Alternate cutt off : 
    2.1.1 Présentation et définition (définition et appli sur les modèles)
    2.1.2 Mesure de l'efficacité de la technique
    2.1.3 Avantages et inconvénients de la technique
  
  2.4 Fonction de coût :
    ...
  2.3 Unequal case weights :
    ...

  2.5 Resamplings methods : 
    2.5.1 Over and donw sampling
    2.5.2 SMOTE
    2.5.3 ROSE
    2.5.4 Comparatif des techniques de resampling
  
  3. Conclusions
  
# Fonctions : 

## performance measure



## Alternate cutoff

```{r}
#changer notation P and N
evoSeuil <- function(x,y,z){
  N<-sum(z==1)
  P<-sum(z==0)
  Error<-NULL
  ErrorI<-NULL
  ErrorII<-NULL
  for(i in 1:101){
  c<-(i-1)/100
  Prediction<-rep(1,nrow(z))
  Prediction[y[,1]>c]<-0
  Error[i]<-sum(Prediction!=x)/nrow(z)
  ErrorI[i]<-sum((Prediction==0)&(x==1))/N
  ErrorII[i]<-sum((Prediction==1)&(x==0))/P
  }
  par(cex=0.7)
  plot((0:100)/100,Error,type="l",xlim=c(0,1),ylim=c(0,1),
  ylab="Taux d'erreur",xlab="Seuil")
  par(new=T)
  plot((0:100)/100,ErrorI,type="l",xlim=c(0,1),ylim=c(0,1),
  ylab="",xlab="",xaxt="n",yaxt="n",col="orange")
  par(new=T)
  plot((0:100)/100,ErrorII,type="l",xlim=c(0,1),ylim=c(0,1),ylab="",xlab="",xaxt="n",yaxt="n",col="blue",lty="dashed")
  legend('topright', legend=c("Erreur ", "Erreur I", "Erreur 2"),
         col=c("black","orange", "blue"), pch=15, bty="n", pt.cex=1, cex= 0.8, horiz=FALSE, inset=c(0.1,0.1))
  title("Evolution des 3 types d'erreur")
}
```

```{r}
changeSeuil <- function(x,y,z,S){
  change_seuil<-rep(1,nrow(z))
  change_seuil[y[,1]>S]<-0
  round(prop.table(table(x,change_seuil),margin=1)*100,1)%>% 
    kable(caption = "Matrice de confusion avec le nouveau seuil") %>% kable_styling()
}
```

  
# Préparation de la base de données 

## En amont 

On charge la base de donnée. Les variables de types "str" sont recodées en facteurs.

```{r}
spotify <- read.csv("spotify_songs.csv", header = TRUE, sep = ",",stringsAsFactors=T)
```

Etant données qu'il n'y a que 15 valeurs manquantes, on décide de supprimer les individus contenant ces valeurs.

```{r}
sum(is.na(spotify))
spotify = na.omit(spotify)
```
Lignes dupliquées : 

Je ne parviens pas à utiliser la fonction distinct de dplyr, aucune lignes supprimées...
Enlever duplicated par track_name n'est pas une bonne idée car on enlève les reprises et cover. Duplicated garde la première valeur de la liste.


```{r}
spot1 <- spotify[!duplicated(spotify$track_id),]
# spot2 <- spotify
# spot2 %>% distinct(track_id)
# spot3 <- spotify[duplicated(spot2$track_id),]
# spot4 <- spotify[!duplicated(spotify$track_name),]
```

Changement du nom des levels:

```{r}
spot1$key <- recode_factor(spot1$key,
  "0" = "C",
  "1" = "Db",
  "2" = "D",
  "3" = "Eb",
  "4" = "E",
  "5" = "F",
  "6" = "Gb",
  "7" = "G",
  "8" = "Ab",
  "9" = "A",
  "10" = "Bb",
  "11" = "B"
)

spot1$mode <- recode_factor(spot1$mode, "0" = "mineur", "1" = "majeur")
```

recodage de la date / regroupement par tranches :

```{r}
spot1$track_album_release_date <- as.Date(spot1$track_album_release_date , format= "%Y")
spot1<- spot1 %>% mutate(year = year(track_album_release_date))
spot1$years <- cut(spot1$year, breaks = c(1956,2000,2010,2015,2018,2020),
                   diag.lab=0,
                   labels = c("1956-2000","2001-2010",
                              "2011-2015","2016-2018","2019-2020"))
```

Suppression de instrumentalness mal codé : 

```{r}
spot1<-spot1[,-c(7,19)]
```

Recodage de track-popularity / regroupement basse/autres :

```{r}
popularity <- cut(spot1$track_popularity, c(-1,12.5,100))
spot_B=cbind(popularity,spot1)
spot_B<-spot_B[,-5]
# spot_B$popularity <- recode_factor(spot_B$popularity,
#                                      "(12.5,100]" = "Autre",
#                                      "(-1,12.5]" = "basse")
spot_B$popularity <- recode_factor(spot_B$popularity,
                                   "(12.5,100]" = 0,
                                   "(-1,12.5]" = 1)
```

On enlève les variables non pertinentes pour la classification : 

```{r}
str(spot_B)
spot_B<-spot_B[,-c(2,3,4,5,6,7,8,10)]
```

## Partitionnement : 

The training and test sets were created using stratiﬁed random sampling.

First, split the training set off:

```{r}
set.seed(42)
split1 <- createDataPartition(spot_B$popularity, p = .7)[[1]]
other <- spot_B[-split1,]
training <- spot_B[ split1,]
```

Now create the evaluation and test sets :

```{r}
set.seed(24)
split2 <- createDataPartition(spot_B$popularity, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]
```

## Normalize/standardize the data :

```{r}
# Estimate preprocessing parameters
preproc.param <- training %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(training)
test.transformed <- preproc.param %>% predict(testing)
evaluation.transformed <- preproc.param %>% predict(evaluation)
```

```{r}
# Determine the predictor names :
predictors <- names(training)[names(training) != "popularity"]
```

```{r}
plot(spot_B$popularity)
```

# First Models : 

## LDA : Linear discriminant analysis

```{r}
# Fit the model
ModLda <- lda(popularity~., data = train.transformed)
# Make predictions
predLda <- ModLda %>% predict(test.transformed)
# Model accuracy
mean(predLda$class==test.transformed$popularity)
```

Confusion matrix and statistic (kappa) with CARET :

```{r}
confusionMatrix(predLda$class, test.transformed$popularity)
```

Courbe ROC et AUC : 

```{r}
pred <- prediction(predLda$posterior[,2], test.transformed$popularity)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
segments(0,0,1,1)
perf<-performance(pred,"auc");perf@y.values[[1]]

```

```{r}
# Pourquoi pas la même qu'au dessus ?????????????
# control and case group ????? (rapport avec réalité et prédiction / levels?)
rocLDA <- roc(test.transformed$popularity, ordered(predLda$class))
plot(rocLDA)
rocLDA$auc
```

## Logistic regression :

```{r}
logit <- glm(popularity~., data= spot_B, family=binomial(link=logit))
```

```{r}
summary(logit)
```

```{r}
stargazer(logit, type="text")
# coeff duration = 0 ??
```

## random forest : 

```{r}
rf <- randomForest(popularity ~ .,
  data = train.transformed, method = "class", 
  parms = list(split = "gini"), na.action = na.roughfix
)

```

## SVM

```{r}
svmFit <- svm(popularity ~ ., data = train.transformed, scale = FALSE, kernel = "radial", cost = 5)
```

```{r}
predict.svm <- predict(svmFit, newdata = test.transformed)
predict.svm
mean(predict.svm==test.transformed$popularity)
confusionMatrix(predict.svm,test.transformed$popularity )
```

## Boosting

# Remedies :

## tune parameters :

### RF

Choix optimal des paramètres avec caret :           

```{r}
# enregistrement d'un cluster avec le package doParallel
library(doParallel)
registerDoParallel(cores = 6)

rangerGrid <- expand.grid(mtry = c(1, 2, 4, 8, 14),
                          min.node.size = c(5, 10, 50, 100),
                          splitrule = "gini"
                          )
ctrlCv <- trainControl(method = "repeatedcv", repeats = 3, number = 5)

system.time(ranger.rf <- train(popularity ~ .,
                              data = train.transformed, method = "ranger",
                              trControl = ctrlCv, tuneGrid = rangerGrid
                              )
            )

# fermeture du cluster
stopImplicitCluster()

# pour CV, paramètre number et reapets ?
# na.action not necessary because all na were ommitted
```

```{r}
ranger.rf
ranger.rf$bestTune
ranger.rf$finalModel
```

### SVM

```{r}
registerDoParallel(cores = 6)

system.time(tuneSvm <- tune(svm, popularity~., data = test.transformed,
                      ranges = list(gamma = c(0.1, 1, 10), cost = 10^(1:3)),
                      tunecontrol = tune.control(nrepeat = 10,
                                                 sampling = "cross",
                                                 cross = 10)))


stopImplicitCluster()
```

```{r}
tuneSvm
```

```{r}
# system.time(tuneSvm <- tune.svm(popularity~., data = train.transformed,
#                                 type = "C-classification",
#                                 kernel = "polynomial", degree =  2,
#                                 cost = 10^(1:3),
#                                 gamma = c(0.1, 1, 10), coef0 = c(0.1, 1, 10),
#                                 class.weights= c("0"=1,"1"=10)))
```

## Alternate cut off :

### LDA 

```{r}
evoSeuil(test.transformed$popularity, predLda$posterior,test.transformed)
```

```{r}
changeSeuil(test.transformed$popularity, predLda$posterior,test.transformed,0.8)
```

## Cost function

## Unequal case weight 

### SVM


```{r}
set.seed(1983)
svmFitW <- svm(popularity ~ ., data = train.transformed, 
              scale = FALSE, 
              kernel = "radial", cost = 10,
              class.weights = c("0" = 1, "1" = 4))
```

```{r}
predict.svmW <- predict(svmFitW, newdata = test.transformed)
mean(predict.svmW==test.transformed$popularity)
confusionMatrix(predict.svmW,test.transformed$popularity )
```


## Resampling methods

### Over and down sampling

### SMOTE 

Synthetic Minority Oversampling Technique

need numeric data only : 

```{r}
train.transformed.num <- train.transformed[, -c(2,5,7,15)]
```


```{r}
smoteData <- SMOTE(train.transformed.num[,-1],train.transformed.num[,1])
```

```{r}
NewdataSmote <- smoteData$data
str(NewdataSmote)
NewdataSmote$class<-as.factor(NewdataSmote$class)
plot(NewdataSmote$class)
```

### ROSE

Random Over-Sampling Examples


```{r}
rose <- ROSE(popularity~. , train.transformed)
```

```{r}
RoseData <- rose$data
```

```{r}
plot(RoseData$popularity)
```


rose.eval ...



