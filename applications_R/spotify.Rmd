---
title: "spotify"
author: "Thibault FUCHEZ"
date: "04/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Package

```{r}
library (tidyverse) # collection of packages for data analysis
library(caret) # Classification And REgression Training
library(pROC) # Tools for visualizing, smoothing and comparing ROC.
library(ROCR) # evaluating and visualizing classifier performance
library(lubridate) # R commands for date-times
library(tidymodels) #  collection of packages for modeling and machine learning using tidyverse principles. pre-process/train/validate
library(MASS) # Modern Applied Statistics with S" for regression and classification
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(randomForest) # ensemble learning method with multitude of decision tree 
library(doParallel) # paralléliser le calcul pour que ce soit plus rapide en créant un cluster de cœurs.
library(parallel) # détection du nombre de coeurs
library(ranger) # A Fast Implementation of Random Forests. (tune rf)
library(e1071) # Misc Functions of the Department of Statistics, Probability Theory Group / for svm, tune, predict, ...
library(kableExtra) # Create Awesome HTML Table
library(smotefamily) # Synthetic Minority Oversampling TEchnique
library(ROSE) # Generation of synthetic data by Randomly Over Sampling Examples
library(gdata) # Various R programming tools for data manipulation / rename object with mv("oldname, newname")
library(naivebayes) #naive Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem
```

```{r}
source("functions_UC.R")
```
  
# Préparation de la base de données 

## En amont 

On charge la base de donnée. Les variables de types "str" sont recodées en facteurs.

```{r}
spotify <- read.csv("spotify_songs.csv", header = TRUE, sep = ",",stringsAsFactors=T)
```

Etant données qu'il n'y a que 15 valeurs manquantes, on décide de supprimer les individus contenant ces valeurs.

```{r}
sum(is.na(spotify))
spotify = na.omit(spotify)
```
Lignes dupliquées : 

```{r}
spot1 <- spotify[!duplicated(spotify$track_id),]
# spot2 <- spotify
# spot2 %>% distinct(track_id)
# spot3 <- spotify[duplicated(spot2$track_id),]
# spot4 <- spotify[!duplicated(spotify$track_name),]
```

Changement du nom des levels:

```{r}
spot1$key <- recode_factor(spot1$key,
  "0" = "C",
  "1" = "Db",
  "2" = "D",
  "3" = "Eb",
  "4" = "E",
  "5" = "F",
  "6" = "Gb",
  "7" = "G",
  "8" = "Ab",
  "9" = "A",
  "10" = "Bb",
  "11" = "B"
)

spot1$mode <- recode_factor(spot1$mode, "0" = "mineur", "1" = "majeur")
```

recodage de la date / regroupement par tranches :

```{r}
spot1$track_album_release_date <- as.Date(spot1$track_album_release_date , format= "%Y")
spot1<- spot1 %>% mutate(year = year(track_album_release_date))
spot1$years <- cut(spot1$year, breaks = c(1956,2000,2010,2015,2018,2020),
                   diag.lab=0,
                   labels = c("1956-2000","2001-2010",
                              "2011-2015","2016-2018","2019-2020"))
```

Suppression de instrumentalness mal codé : 

```{r}
spot1<-spot1[,-c(7,19)]
```

Recodage de track-popularity / regroupement basse/autres :

```{r}
popularity <- cut(spot1$track_popularity, c(-1,12.5,100))
spot_B=cbind(popularity,spot1)
spot_B<-spot_B[,-5]
# spot_B$popularity <- recode_factor(spot_B$popularity,
#                                      "(12.5,100]" = "Autre",
#                                      "(-1,12.5]" = "basse")
spot_B$popularity <- recode_factor(spot_B$popularity,
                                   "(12.5,100]" = 0,
                                   "(-1,12.5]" = 1)
```

On enlève les variables non pertinentes pour la classification : 

```{r}
str(spot_B)
spot_B<-spot_B[,-c(2,3,4,5,6,7,8,10)]
```

## Partitionnement : 

The training and test sets were created using stratiﬁed random sampling.

First, split the training set off:

```{r}
set.seed(42)
split1 <- createDataPartition(spot_B$popularity, p = .7)[[1]]
other <- spot_B[-split1,]
training <- spot_B[ split1,]
```

Now create the evaluation and test sets :

```{r}
set.seed(24)
split2 <- createDataPartition(spot_B$popularity, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]
```

## Normalize/standardize the data :

```{r}
# Estimate preprocessing parameters
preproc.param <- training %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(training)
test.transformed <- preproc.param %>% predict(testing)
evaluation.transformed <- preproc.param %>% predict(evaluation)
```

```{r}
# Determine the predictor names :
predictors <- names(training)[names(training) != "popularity"]
```

```{r}
plot(spot_B$popularity)
```

# First Models : 

## LDA : Linear discriminant analysis

```{r}
# Fit the model
ModLda <- lda(popularity~., data = train.transformed)
# Make predictions
predLda <- ModLda %>% predict(test.transformed)
```

```{r}
perf.measure(predLda$class, test.transformed$popularity, test.transformed)
```

```{r}
RocAuc(predLda, test.transformed$popularity, "autre")
```

Pour le moment, Je conserve les deux chunks ci-dessous pour comparer avex les résultats de mes fonctions. 

```{r}
# Avec CARET
confusionMatrix(predLda$class, test.transformed$popularity)
```

```{r}
# Avec proc 

# Pourquoi pas la même qu'au dessus ?????????????
# control and case group ????? (rapport avec réalité et prédiction / levels?)
rocLDA <- roc(test.transformed$popularity, ordered(predLda$class))
plot(rocLDA)
rocLDA$auc
```

## Logistic regression :

```{r}

Modlogit <- glm(popularity~., data= train.transformed, family=binomial(link=logit))
```

```{r}
summary(Modlogit)
```

```{r}
stargazer(logit, type="text")
```

technique 1 : 

```{r}
# Estimate the audible probability
problog <- predict(Modlogit, train.transformed, type = 'response')
```

```{r}
#Find the audible probability of the average prospect
average <- sum(spot_B$popularity=="1")/nrow(spot_B)
```

```{r}
#Predict a inaudible classement if probability of audibility is lower than average (0.1924379)
predlog <- ifelse(problog < average, 1, 0)
```

```{r}
# Calculate the model's accuracy
mean(predlog == train.transformed$popularity)
```

technique 2 : 

```{r}
# pr verif 
table(true = train.transformed$popularity, 
      pred = round(fitted(Modlogit)))
```

```{r}
mean(fitted(Modlogit))
average
```

performance : 

```{r}
perf.measure(predlog, train.transformed$popularity, train.transformed)
```


```{r}
perf.measure(round(fitted(Modlogit)),
             train.transformed$popularity, train.transformed)
```

```{r}
RocAuc(fitted(Modlogit), train.transformed$popularity, "logit")
```

## random forest : 

```{r}
Modrf <- randomForest(popularity ~ .,
  data = train.transformed, method = "class", 
  parms = list(split = "gini"), na.action = na.roughfix
)

```

## SVM

```{r}
svmFit <- svm(popularity ~ ., data = train.transformed, scale = FALSE, kernel = "radial", cost = 5)
```

```{r}
predict.svm <- predict(svmFit, newdata = test.transformed)
predict.svm
mean(predict.svm==test.transformed$popularity)
confusionMatrix(predict.svm,test.transformed$popularity )
```

## Boosting

# Remedies :

## tune parameters :

### RF

Choix optimal des paramètres avec caret :           

```{r}
# enregistrement d'un cluster avec le package doParallel
library(doParallel)
registerDoParallel(cores = 6)

rangerGrid <- expand.grid(mtry = c(1, 2, 4, 8, 14),
                          min.node.size = c(5, 10, 50, 100),
                          splitrule = "gini"
                          )
ctrlCv <- trainControl(method = "repeatedcv", repeats = 3, number = 5)

system.time(ranger.rf <- train(popularity ~ .,
                              data = train.transformed, method = "ranger",
                              trControl = ctrlCv, tuneGrid = rangerGrid
                              )
            )

# fermeture du cluster
stopImplicitCluster()

# pour CV, paramètre number et reapets ?
# na.action not necessary because all na were ommitted
```

```{r}
ranger.rf
ranger.rf$bestTune
ranger.rf$finalModel
```

### SVM

```{r}
registerDoParallel(cores = 6)

system.time(tuneSvm <- tune(svm, popularity~., data = test.transformed,
                      ranges = list(gamma = c(0.1, 1, 10), cost = 10^(1:3)),
                      tunecontrol = tune.control(nrepeat = 10,
                                                 sampling = "cross",
                                                 cross = 10)))


stopImplicitCluster()
```

```{r}
tuneSvm
```

```{r}
# system.time(tuneSvm <- tune.svm(popularity~., data = train.transformed,
#                                 type = "C-classification",
#                                 kernel = "polynomial", degree =  2,
#                                 cost = 10^(1:3),
#                                 gamma = c(0.1, 1, 10), coef0 = c(0.1, 1, 10),
#                                 class.weights= c("0"=1,"1"=10)))
```

## Alternate cut off :

On expliquera le procédé.
En conclusion, on explicitera que cela nous coute trop en terme d'erreur globale si l'on veut un bon pouvoir de détection. 

### LDA 

```{r}
evoSeuil(predLda, test.transformed$popularity, test.transformed, "autre")
```

```{r}
changeSeuil(predLda, test.transformed$popularity ,test.transformed, 0.2, "autre")
```

### Logit 

```{r}
evoSeuil(problog, train.transformed$popularity, train.transformed, "logit")
```

```{r}
logseuil<-changeSeuil(problog, train.transformed$popularity, train.transformed,0.3, "logit")
```

```{r}
perf.measure(predlog, train.transformed$popularity, train.transformed)
```


## Cost function

## Unequal case weight 

### SVM

```{r}
set.seed(1983)
svmFitW <- svm(popularity ~ ., data = train.transformed, 
              scale = FALSE, 
              kernel = "radial", cost = 10,
              class.weights = c("0" = 1, "1" = 4))
```

```{r}
predict.svmW <- predict(svmFitW, newdata = test.transformed)
mean(predict.svmW==test.transformed$popularity)
confusionMatrix(predict.svmW,test.transformed$popularity )
```

## Resampling methods

### Over and down sampling

### SMOTE 

Synthetic Minority Oversampling Technique

need numeric data only : 

```{r}
train.transformed.num <- train.transformed[, -c(2,5,7,15)]
```

```{r}
smoteData <- SMOTE(train.transformed.num[,-1],train.transformed.num[,1])
```

```{r}
NewdataSmote <- smoteData$data
str(NewdataSmote)
NewdataSmote$class<-as.factor(NewdataSmote$class)
plot(NewdataSmote$class)
```

### ROSE

Random Over-Sampling Examples

```{r}
rose <- ROSE(popularity~. , train.transformed)
```

```{r}
RoseData <- rose$data
```

```{r}
plot(RoseData$popularity)
```

rose.eval ...



