---
title: "spotify"
author: "Thibault FUCHEZ"
date: "04/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Package

```{r}
library (tidyverse) # collection of packages for data analysis
library(caret) # Classification And REgression Training
library(pROC) # Tools for visualizing, smoothing and comparing ROC.
library(ROCR) # evaluating and visualizing classifier performance
library(lubridate) # R commands for date-times
library(tidymodels) #  collection of packages for modeling and machine learning using tidyverse principles. pre-process/train/validate
library(MASS) # Modern Applied Statistics with S" for regression and classification
library(stargazer) # Well-Formatted Regression and Summary Statistics Tables
library(randomForest) # ensemble learning method with multitude of decision tree 
library(doParallel) # paralléliser le calcul pour que ce soit plus rapide en créant un cluster de cœurs.
library(parallel) # détection du nombre de coeurs
library(ranger) # A Fast Implementation of Random Forests. (tune rf)
library(e1071) # Misc Functions of the Department of Statistics, Probability Theory Group / for svm, tune, predict, ...
library(kableExtra) # Create Awesome HTML Table
library(smotefamily) # Synthetic Minority Oversampling TEchnique
library(ROSE) # Generation of synthetic data by Randomly Over Sampling Examples
library(gdata) # Various R programming tools for data manipulation / rename object with mv("oldname, newname")
```

# idée de plan et qq notes 

Penser à citer les articles et à expliciter rapidement les notions mathéatiques derrière les concepts (comment le modèle apprend -formule et grap)

O. Préparation des bases de données et création des fonctions utilisée par la suite  ??

1. Définition problèmatique : 
  1.1 Préparation des bases de données
  1.2 Création des fonctions pour automatiser le code 
  1.3 Observation des résultats de classification sur échantillons déséquilibrés (3 ou 4 base de données). On fait tourner les modèles et on observe que la machine apprend mal avec des modèles basés sur une classe déséquilibrée. 

2. Solutions : 

  2.1 Optimiser les paramètres : 
    2.1.1 Présentation et définition (définition et appli sur les modèles)
    2.1.2 Mesure de l'efficacité de la technique
    2.1.3 Avantages et inconvénients de la technique
  
  2.2 Alternate cutt off : 
    2.1.1 Présentation et définition (définition et appli sur les modèles)
    2.1.2 Mesure de l'efficacité de la technique
    2.1.3 Avantages et inconvénients de la technique
  
  2.4 Fonction de coût :
    ...
  2.3 Unequal case weights :
    ...

  2.5 Resamplings methods : 
    2.5.1 Over and donw sampling
    2.5.2 SMOTE
    2.5.3 ROSE
    2.5.4 Comparatif des techniques de resampling
  
  3. Conclusions
  
# Fonctions : 

## performance measure

accuracy , errors, roc, kappa, lift curves, ...

On définit trois types d'erreurs : 

* erreur globale de classement : $(FP +FN)/total$

* erreur de type 1 : $FP/N$

* erreur de type 2 : $FN/P$

kappa formula and definition : 

 > The Kappa statistic (also known as Cohen’s Kappa) was originally designed to assess the agreement between two raters (Cohen 1960). Kappa takes into account the accuracy that would be generated simply by chance. (wikipedia)
 
the kappa can range from -1 to +1 

$$ K = \frac{Pr(a) - Pr(e)}{1 - Pr(e)}$$
Where $Pr(a)$ represents the actual observed agree-ment, and $Pr(e)$ represents chance agreement. We calculate this two ratio with the confusion matrix. 

```{r}
perf.measure <- function(pred ,realCl, real )
{
  MatConf <- table(pred,realCl) %>% addmargins %>% 
    kable(caption = "matrice de confusion")%>% kable_styling
  P <- sum(realCl==1)
  N <- sum(realCl==0)
  n <- P+N
  Pp <- sum(pred==1)
  Np <- sum(pred==0)
  pre <- (((N*Np)/n)+((P*Pp)/n))/n
  pra <- sum((pred==0)&(real==0))+sum((pred==1)&(real==1))/n
  kappa <- (pra - pre)/(1 - pre)
  error <- sum(pred!=realCl)/nrow(real)
  FPrate <- sum((pred==1)&(real==0))/N
  FNrate <- sum((pred==0)&(real==1))/P
  accuracy <- 1 - error
  out <- c(error, accuracy, FPrate, FNrate, kappa)
  names(out) <- c("error", "accuracy", "FP/N", "FN/P", "kappa")
  perfM <- out%>%kable(caption = "Performance measures",
                       col.names = "value") %>% kable_styling()
  print(perfM)
  print(MatConf)
}
```

Courbe ROC

```{r}
RocAuc <- function(pred, realCl, mod){
  if (mod == "logit")
    {pred <- prediction(round(pred),realCl)}
  else 
    {pred <- prediction(pred$posterior[,2], realCl)}
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")
  plot(perf, col=rainbow(10))
  segments(0,0,1,1)
  perf<-performance(pred,"auc");perf@y.values[[1]]
}
```

## Alternate cutoff

```{r}
evoSeuil <- function(pred, realCl,real, mod){
  N<-sum(realCl==0)
  P<-sum(realCl==1)
  Error<-NULL
  FPr<-NULL
  FNr<-NULL
  for(i in 1:101){
  c<-(i-1)/100
  Prediction<-rep(0,nrow(real))
  if (mod=="logit")
  {Prediction[pred>c]<-1}
  else
  {Prediction[pred$posterior[,2]>c]<-1}
  Error[i]<-sum(Prediction!=realCl)/nrow(real)
  FPr[i]<-sum((Prediction==1)&(realCl==0))/N
  FNr[i]<-sum((Prediction==0)&(realCl==1))/P
  }
  par(cex=0.7)
  plot((0:100)/100,Error,type="l",xlim=c(0,1),ylim=c(0,1),
  ylab="Taux d'erreur",xlab="Seuil")
  par(new=T)
  plot((0:100)/100,FPr,type="l",xlim=c(0,1),ylim=c(0,1),
  ylab="",xlab="",xaxt="n",yaxt="n",col="orange")
  par(new=T)
  plot((0:100)/100,FNr,type="l",xlim=c(0,1),ylim=c(0,1),ylab="",xlab="",xaxt="n",yaxt="n",col="blue",lty="dashed")
  legend('topright', legend=c("Error ", "FP rate", "FN rate"),
         col=c("black","orange", "blue"), pch=15, bty="n", pt.cex=1, cex= 0.8, horiz=FALSE, inset=c(0.1,0.1))
  title("Evolution des 3 types d'erreur")
}
```

```{r}
changeSeuil <- function(pred, realCl, real, seuil, mod){
  change_seuil<-rep(0,nrow(real))
  if (mod == "logit")
  {change_seuil[pred>seuil]<-1}
  else
  {change_seuil[pred$posterior[,2]>seuil]<-1}
  table(change_seuil,realCl) %>% addmargins %>% 
    kable(caption = "matrice de confusion avec le nouveau seuil") %>%
    kable_styling
}
```
  
# Préparation de la base de données 

## En amont 

On charge la base de donnée. Les variables de types "str" sont recodées en facteurs.

```{r}
spotify <- read.csv("spotify_songs.csv", header = TRUE, sep = ",",stringsAsFactors=T)
```

Etant données qu'il n'y a que 15 valeurs manquantes, on décide de supprimer les individus contenant ces valeurs.

```{r}
sum(is.na(spotify))
spotify = na.omit(spotify)
```
Lignes dupliquées : 

Je ne parviens pas à utiliser la fonction distinct de dplyr, aucune lignes supprimées...
Enlever duplicated par track_name n'est pas une bonne idée car on enlève les reprises et cover. Duplicated garde la première valeur de la liste.

```{r}
spot1 <- spotify[!duplicated(spotify$track_id),]
# spot2 <- spotify
# spot2 %>% distinct(track_id)
# spot3 <- spotify[duplicated(spot2$track_id),]
# spot4 <- spotify[!duplicated(spotify$track_name),]
```

Changement du nom des levels:

```{r}
spot1$key <- recode_factor(spot1$key,
  "0" = "C",
  "1" = "Db",
  "2" = "D",
  "3" = "Eb",
  "4" = "E",
  "5" = "F",
  "6" = "Gb",
  "7" = "G",
  "8" = "Ab",
  "9" = "A",
  "10" = "Bb",
  "11" = "B"
)

spot1$mode <- recode_factor(spot1$mode, "0" = "mineur", "1" = "majeur")
```

recodage de la date / regroupement par tranches :

```{r}
spot1$track_album_release_date <- as.Date(spot1$track_album_release_date , format= "%Y")
spot1<- spot1 %>% mutate(year = year(track_album_release_date))
spot1$years <- cut(spot1$year, breaks = c(1956,2000,2010,2015,2018,2020),
                   diag.lab=0,
                   labels = c("1956-2000","2001-2010",
                              "2011-2015","2016-2018","2019-2020"))
```

Suppression de instrumentalness mal codé : 

```{r}
spot1<-spot1[,-c(7,19)]
```

Recodage de track-popularity / regroupement basse/autres :

```{r}
popularity <- cut(spot1$track_popularity, c(-1,12.5,100))
spot_B=cbind(popularity,spot1)
spot_B<-spot_B[,-5]
# spot_B$popularity <- recode_factor(spot_B$popularity,
#                                      "(12.5,100]" = "Autre",
#                                      "(-1,12.5]" = "basse")
spot_B$popularity <- recode_factor(spot_B$popularity,
                                   "(12.5,100]" = 0,
                                   "(-1,12.5]" = 1)
```

On enlève les variables non pertinentes pour la classification : 

```{r}
str(spot_B)
spot_B<-spot_B[,-c(2,3,4,5,6,7,8,10)]
```

## Partitionnement : 

The training and test sets were created using stratiﬁed random sampling.

First, split the training set off:

```{r}
set.seed(42)
split1 <- createDataPartition(spot_B$popularity, p = .7)[[1]]
other <- spot_B[-split1,]
training <- spot_B[ split1,]
```

Now create the evaluation and test sets :

```{r}
set.seed(24)
split2 <- createDataPartition(spot_B$popularity, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]
```

## Normalize/standardize the data :

```{r}
# Estimate preprocessing parameters
preproc.param <- training %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(training)
test.transformed <- preproc.param %>% predict(testing)
evaluation.transformed <- preproc.param %>% predict(evaluation)
```

```{r}
# Determine the predictor names :
predictors <- names(training)[names(training) != "popularity"]
```

```{r}
plot(spot_B$popularity)
```

# First Models : 

## LDA : Linear discriminant analysis

```{r}
# Fit the model
ModLda <- lda(popularity~., data = train.transformed)
# Make predictions
predLda <- ModLda %>% predict(test.transformed)
```

```{r}
perf.measure(predLda$class, test.transformed$popularity, test.transformed)
```

```{r}
RocAuc(predLda, test.transformed$popularity, "autre")
```

Pour le moment, Je conserve les deux chunks ci-dessous pour comparer avex les résultats de mes fonctions. 

```{r}
# Avec CARET
confusionMatrix(predLda$class, test.transformed$popularity)
```

```{r}
# Avec proc 

# Pourquoi pas la même qu'au dessus ?????????????
# control and case group ????? (rapport avec réalité et prédiction / levels?)
rocLDA <- roc(test.transformed$popularity, ordered(predLda$class))
plot(rocLDA)
rocLDA$auc
```

## Logistic regression :

```{r}
Modlogit <- glm(popularity~., data= train.transformed, family=binomial(link=logit))
```

```{r}
predlog <- predict(Modlogit, type = 'response')
```

```{r}
summary(Modlogit)
```

```{r}
stargazer(logit, type="text")
```

```{r}
# pr verif 
table(true = train.transformed$popularity, pred = round(fitted(Modlogit)))
```

```{r}
perf.measure(round(fitted(Modlogit)),
             train.transformed$popularity, train.transformed)
```

```{r}
RocAuc(fitted(Modlogit), train.transformed$popularity, "logit")
```

## random forest : 

```{r}
Modrf <- randomForest(popularity ~ .,
  data = train.transformed, method = "class", 
  parms = list(split = "gini"), na.action = na.roughfix
)

```

## SVM

```{r}
svmFit <- svm(popularity ~ ., data = train.transformed, scale = FALSE, kernel = "radial", cost = 5)
```

```{r}
predict.svm <- predict(svmFit, newdata = test.transformed)
predict.svm
mean(predict.svm==test.transformed$popularity)
confusionMatrix(predict.svm,test.transformed$popularity )
```

## Boosting

# Remedies :

## tune parameters :

### RF

Choix optimal des paramètres avec caret :           

```{r}
# enregistrement d'un cluster avec le package doParallel
library(doParallel)
registerDoParallel(cores = 6)

rangerGrid <- expand.grid(mtry = c(1, 2, 4, 8, 14),
                          min.node.size = c(5, 10, 50, 100),
                          splitrule = "gini"
                          )
ctrlCv <- trainControl(method = "repeatedcv", repeats = 3, number = 5)

system.time(ranger.rf <- train(popularity ~ .,
                              data = train.transformed, method = "ranger",
                              trControl = ctrlCv, tuneGrid = rangerGrid
                              )
            )

# fermeture du cluster
stopImplicitCluster()

# pour CV, paramètre number et reapets ?
# na.action not necessary because all na were ommitted
```

```{r}
ranger.rf
ranger.rf$bestTune
ranger.rf$finalModel
```

### SVM

```{r}
registerDoParallel(cores = 6)

system.time(tuneSvm <- tune(svm, popularity~., data = test.transformed,
                      ranges = list(gamma = c(0.1, 1, 10), cost = 10^(1:3)),
                      tunecontrol = tune.control(nrepeat = 10,
                                                 sampling = "cross",
                                                 cross = 10)))


stopImplicitCluster()
```

```{r}
tuneSvm
```

```{r}
# system.time(tuneSvm <- tune.svm(popularity~., data = train.transformed,
#                                 type = "C-classification",
#                                 kernel = "polynomial", degree =  2,
#                                 cost = 10^(1:3),
#                                 gamma = c(0.1, 1, 10), coef0 = c(0.1, 1, 10),
#                                 class.weights= c("0"=1,"1"=10)))
```

## Alternate cut off :

### LDA 

```{r}
evoSeuil(predLda, test.transformed$popularity, test.transformed, "autre")
```

```{r}
changeSeuil(predLda, test.transformed$popularity ,test.transformed, 0.2, "autre")
```

### Logit 

```{r}
evoSeuil(predlog, train.transformed$popularity, train.transformed, "logit")
```

```{r}
changeSeuil(predlog, train.transformed$popularity, train.transformed,0.3, "logit")
```

## Cost function

## Unequal case weight 

### SVM

```{r}
set.seed(1983)
svmFitW <- svm(popularity ~ ., data = train.transformed, 
              scale = FALSE, 
              kernel = "radial", cost = 10,
              class.weights = c("0" = 1, "1" = 4))
```

```{r}
predict.svmW <- predict(svmFitW, newdata = test.transformed)
mean(predict.svmW==test.transformed$popularity)
confusionMatrix(predict.svmW,test.transformed$popularity )
```

## Resampling methods

### Over and down sampling

### SMOTE 

Synthetic Minority Oversampling Technique

need numeric data only : 

```{r}
train.transformed.num <- train.transformed[, -c(2,5,7,15)]
```

```{r}
smoteData <- SMOTE(train.transformed.num[,-1],train.transformed.num[,1])
```

```{r}
NewdataSmote <- smoteData$data
str(NewdataSmote)
NewdataSmote$class<-as.factor(NewdataSmote$class)
plot(NewdataSmote$class)
```

### ROSE

Random Over-Sampling Examples

```{r}
rose <- ROSE(popularity~. , train.transformed)
```

```{r}
RoseData <- rose$data
```

```{r}
plot(RoseData$popularity)
```

rose.eval ...



